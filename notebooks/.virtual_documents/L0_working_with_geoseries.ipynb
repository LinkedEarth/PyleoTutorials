





%load_ext watermark

import pyleoclim as pyleo
from pylipd.lipd import LiPD
import pandas as pd
import numpy as np





data_path = '../data/Crystal.McCabe-Glynn.2013.lpd'
D = LiPD()
D.load(data_path)


df = D.get_timeseries_essentials(D.get_all_dataset_names()[0])


df





df.columns






metadata_dict={'time': df['time_values'].iloc[0],
              'value': df['paleoData_values'].iloc[0],
              'time_name': 'Time', 'label': df['dataSetName'].iloc[0],
              'time_unit': 'year CE',
              'value_name': df['paleoData_variableName'].iloc[0],
              'value_unit': df['paleoData_units'].iloc[0],
              'lat':df['geo_meanLat'].iloc[0],
              'lon':df['geo_meanLon'].iloc[0], 
              'elevation': df['geo_meanElev'].iloc[0],    
               'archiveType': df['archiveType'].iloc[0],
               'observationType': df['paleoData_proxy'].iloc[0],
              }

ts = pyleo.GeoSeries(**metadata_dict)





ts.value_name = '$\delta^{18}$O'
ts.value_unit = "â€° VPDB"


ts.plot()





ts.map()





ts.map(edgecolor='black', scatter_kwargs ={'linewidth':2})





ts.dashboard()





import json
import requests
import io


url = 'https://linkedearth.graphdb.mint.isi.edu/repositories/LiPDVerse3'

query = """

PREFIX le: <http://linked.earth/ontology#>
PREFIX wgs: <http://www.w3.org/2003/01/geo/wgs84_pos#>

select ?val ?timeval ?varunits ?timeunits ?varname ?timevarname ?dsname ?lat ?lon ?alt ?archive ?proxy where { 
    
    ?ds le:name ?dsname .
        OPTIONAL {?ds le:proxyArchiveType ?archive .} 
    ?ds le:includesPaleoData ?data .
    
    ?ds le:collectedFrom ?loc . 
    ?loc wgs:lat ?lat .
        FILTER(?lat<60 && ?lat>20) 
    ?loc wgs:long ?lon .
    ?loc wgs:alt ?alt .
    
    ?data le:foundInMeasurementTable ?table .
    ?table le:includesVariable ?var .
    ?var le:name ?varname .
        FILTER regex(?varname, "temperature.*") .
    ?var le:hasValues ?val .
    ?var le:hasUnits ?varunits .
        VALUES ?varunits {"degC"} .
    ?var le:proxy ?proxy .
    ?var le:partOfCompilation ?comp .
    ?comp le:name "Pages2kTemperature" .
            
    
    ?table le:includesVariable ?timevar .
    ?timevar le:name ?timevarname .
        VALUES ?timevarname {"year"} .
    ?timevar le:hasValues ?timeval .
        OPTIONAL{?timevar le:hasUnits ?timeunits .}       
}

"""

response = requests.post(url, data = {'query': query})

data = io.StringIO(response.text)
df = pd.read_csv(data, sep=",")

# Make list from the values string
df['val']=df['val'].apply(lambda row : np.fromstring(row.strip("[]"), sep=','))
df['timeval']=df['timeval'].apply(lambda row : np.fromstring(row.strip("[]"), sep=','))

df.head()





ts_list = []
for _, row in df.iterrows():
    ts_list.append(pyleo.GeoSeries(time=row['timeval'],value=row['val'],
                            time_name='Year',value_name=row['varname'],
                            time_unit=row['timeunits'], value_unit=row['varunits'],
                            lat = row['lat'], lon = row['lon'], 
                            elevation = row['alt'],   
                            archiveType = row['archive'],
                            observationType=row['proxy'],       
                            label=row['dsname']+'_'+row['proxy'], verbose = False)) 





pages2k = pyleo.MultipleGeoSeries(ts_list,time_unit='year CE')    
pages2k.stackplot(ylabel_fontsize=0)





pages2k.map()





NAm_coord = {'central_latitude':30, 'central_longitude':-60}
pages2k.map(projection='Orthographic',proj_default=NAm_coord) 





pages2k.map(projection='Orthographic', size='elevation', proj_default=NAm_coord) 





pages2k.map(projection='Orthographic', hue = 'observationType', proj_default=NAm_coord) 





pages2k.map(projection='Orthographic',hue='observationType',
                       size='elevation', proj_default=NAm_coord, figsize=[18, 8]) 





ts.map_neighbors(pages2k)





ts.map_neighbors(pages2k, radius=5000)





%watermark -n -u -v -iv -w


ts = pyleo.utils.datasets.load_dataset('EDC-dD')
fig, ax = ts.map(edgecolor='black')



